<!-- BEGIN TITLE -->
# Every letter is a number
<!-- END TITLE -->

<!-- BEGIN BODY -->
If letters are represented in computers they are stored as numbers. To encode them every letter got its own decimal number between 0 and 127. The "H", for example, is encoded as the 72.
The string "Hello world" is stored as a sequence of numbers.

```
 H  e   l   l   o  space  w   o   r   l   d
72 101 108 108 111   32  119 111 114 108 100
```

Since things are stored binary in computers, those numbers are translated in binary code.
In this way are not just the capital letters encoded but also the lowercase letters, the digits 0-9 and punctuation symbols.

This very common character encoding is called ASCII (American Standard Code for Information Interchange).
Today, the international standard for encoding is called Unicode. It is way bigger than ASCII, such that (in some days) every possible character of every language will have its own digital code.

<!-- END BODY -->


![Image title](../images/image-122-ascii.png)


## Optional text
<!-- BEGIN OPTIONAL -->

<!-- END OPTIONAL -->



## Author
<!-- BEGIN AUTHOR -->
Rebecca Dold
<!-- END AUTHOR -->
